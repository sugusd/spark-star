##### 插件安装

###### 下载代码

```bash
git clone https://github.com/ispong/spark-star.git
```

###### 配置编译环境变量

```bash
vim /etc/profile
```

```bash
export HADOOP_HOME=/opt/hadoop
export SPARK_HOME=/opt/spark
export HADOOP_CLASSPATH=/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/* 
export HIVE_HOME=/opt/hive
```

```bash
source /etc/profile
```

###### 编译项目

```bash
bash build.sh
```

###### 配置环境变量

```bash
sudo ln -s /home/ispong/spark-star/build/star /opt/spark-star
sudo vim /etc/profile
```

```bash
export SPARK_STAR_HOME=/opt/spark-star
export PATH=$PATH:$SPARK_STAR_HOME/bin
```

```bash
source /etc/profile
```

###### 配置插件文件

```bash
spark-star config
```

```yaml
server:
  port: 30156 
  
logging:
  group:
    star: com.isxcode.star
  level:
    star: debug

star:
  plugin:
    server-key: star-key 
    app-name-prefix: spark-star 
    master: yarn 
    spark-config:
      spark.ui.port: 30128
      spark.executor.memory: 4g
      spark.executor.cores: 1
      spark.driver.memory: 1g
      spark.num.executors: 1
      hive.metastore.uris: thrift://localhost:9083
```

###### 插件启动

```bash

```
