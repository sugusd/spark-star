##### 插件安装

###### 下载代码

```bash
git clone https://github.com/ispong/spark-star.git
```

###### 配置编译环境变量

```bash
vim /etc/profile
```

```bash
export HADOOP_HOME=/opt/hadoop
export SPARK_HOME=/opt/spark
export HADOOP_CLASSPATH=/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/* 
export HIVE_HOME=/opt/hive
```

```bash
source /etc/profile
```

###### 编译项目

```bash
bash build.sh
```

###### 配置环境变量

```bash
sudo ln -s /home/ispong/spark-star/build/star /opt/spark-star
sudo vim /etc/profile
```

```bash
export SPARK_STAR_HOME=/opt/spark-star
export PATH=$PATH:$SPARK_STAR_HOME/bin
```

```bash
source /etc/profile
```

###### 配置插件文件

```bash
spark-star config
```

```yaml
server:
  port: 30156 
  
logging:
  group:
    star: com.isxcode.star
  level:
    star: debug

star:
  plugin:
    server-key: star-key 
    app-name-prefix: spark-star 
    master: yarn 
    spark-config:
      spark.ui.port: 30128
      spark.executor.memory: 4g
      spark.executor.cores: 1
      spark.driver.memory: 1g
      spark.num.executors: 1
      hive.metastore.uris: thrift://localhost:9083
```

###### 插件启动

```bash
spark-star start
```

```log
2022-08-02 16:00:09,437 INFO util.ShutdownHookManager: Shutdown hook called
2022-08-02 16:00:09,437 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-06945eff-a9cd-4f0f-b39a-9c3dfbe6fcb8
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/dehoop/spark-star/build/star/lib/star-plugin.jar!/BOOT-INF/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/dehoop/spark-star/build/star/lib/star-plugin.jar!/BOOT-INF/lib/log4j-slf4j-impl-2.12.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.2.7.RELEASE)

2022-08-02 16:03:49,336 INFO plugin.StarApplication: Starting StarApplication v0.0.1 on dcloud with PID 63553 (/home/dehoop/spark-star/build/star/lib/star-plugin.jar started by dehoop in /home/dehoop/spark-star/build/star/bin)
2022-08-02 16:03:49,336 INFO plugin.StarApplication: The following profiles are active: star
2022-08-02 16:03:50,620 INFO support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker: Bean 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties' of type [org.springframework.boot.autoconfigure.kafka.KafkaProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-08-02 16:03:50,621 INFO support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker: Bean 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration' of type [org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-08-02 16:03:50,633 INFO support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker: Bean 'kafkaProducerFactory' of type [org.springframework.kafka.core.DefaultKafkaProducerFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-08-02 16:03:50,635 INFO support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker: Bean 'kafkaProducerListener' of type [org.springframework.kafka.support.LoggingProducerListener] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-08-02 16:03:50,656 INFO support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker: Bean 'kafkaTemplate' of type [org.springframework.kafka.core.KafkaTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-08-02 16:03:50,660 INFO support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker: Bean 'star.plugin-com.isxcode.star.common.properties.StarPluginProperties' of type [com.isxcode.star.common.properties.StarPluginProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-08-02 16:03:50,660 INFO support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker: Bean 'starThreadConfig' of type [com.isxcode.star.plugin.config.StarThreadConfig$$EnhancerBySpringCGLIB$$36d9657d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-08-02 16:03:51,265 INFO tomcat.TomcatWebServer: Tomcat initialized with port(s): 30156 (http)
2022-08-02 16:03:51,281 INFO http11.Http11NioProtocol: Initializing ProtocolHandler ["http-nio-30156"]
2022-08-02 16:03:51,281 INFO core.StandardService: Starting service [Tomcat]
2022-08-02 16:03:51,281 INFO core.StandardEngine: Starting Servlet engine: [Apache Tomcat/9.0.34]
2022-08-02 16:03:51,365 INFO [localhost].[/spark-star]: Initializing Spring embedded WebApplicationContext
2022-08-02 16:03:51,365 INFO context.ContextLoader: Root WebApplicationContext: initialization completed in 1975 ms
2022-08-02 16:03:51,806 INFO conf.HiveConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2022-08-02 16:03:52,035 WARN util.Utils: Your hostname, dcloud resolves to a loopback address: 127.0.0.1; using 192.168.66.66 instead (on interface enp4s0)
2022-08-02 16:03:52,035 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022-08-02 16:03:52,248 INFO spark.SparkContext: Running Spark version 3.1.1
2022-08-02 16:03:52,373 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-08-02 16:03:52,461 INFO resource.ResourceUtils: ==============================================================
2022-08-02 16:03:52,461 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2022-08-02 16:03:52,461 INFO resource.ResourceUtils: ==============================================================
2022-08-02 16:03:52,462 INFO spark.SparkContext: Submitted application: spark-star
2022-08-02 16:03:52,488 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-08-02 16:03:52,501 INFO resource.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-08-02 16:03:52,503 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2022-08-02 16:03:52,558 INFO spark.SecurityManager: Changing view acls to: dehoop
2022-08-02 16:03:52,559 INFO spark.SecurityManager: Changing modify acls to: dehoop
2022-08-02 16:03:52,559 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-02 16:03:52,559 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-02 16:03:52,560 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dehoop); groups with view permissions: Set(); users  with modify permissions: Set(dehoop); groups with modify permissions: Set()
2022-08-02 16:03:52,897 INFO util.Utils: Successfully started service 'sparkDriver' on port 33768.
2022-08-02 16:03:52,928 INFO spark.SparkEnv: Registering MapOutputTracker
2022-08-02 16:03:52,955 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-08-02 16:03:52,971 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-08-02 16:03:52,971 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-08-02 16:03:52,998 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-08-02 16:03:53,009 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-590be0e1-2a31-4c39-872f-edc0136d6783
2022-08-02 16:03:53,039 INFO memory.MemoryStore: MemoryStore started with capacity 912.3 MiB
2022-08-02 16:03:53,064 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-08-02 16:03:53,125 INFO util.log: Logging initialized @5338ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-08-02 16:03:53,171 INFO server.Server: jetty-9.4.36.v20210114; built: 2021-01-14T16:44:28.689Z; git: 238ec6997c7806b055319a6d11f8ae7564adc0de; jvm 1.8.0_312-b07
2022-08-02 16:03:53,185 INFO server.Server: Started @5398ms
2022-08-02 16:03:53,212 INFO server.AbstractConnector: Started ServerConnector@381d281a{HTTP/1.1, (http/1.1)}{0.0.0.0:30128}
2022-08-02 16:03:53,212 INFO util.Utils: Successfully started service 'SparkUI' on port 30128.
2022-08-02 16:03:53,227 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@376a0d86{/jobs,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,229 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4bff7da0{/jobs/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,230 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@536dbea0{/jobs/job,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,230 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@21d03963{/jobs/job/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,231 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18ece7f4{/stages,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,231 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1cf56a1c{/stages/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,231 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c5ae43b{/stages/stage,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,232 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2e570ded{/stages/stage/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,232 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@81d9a72{/stages/pool,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,233 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1169afe1{/stages/pool/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,233 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4808bc9b{/storage,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,234 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca923bb{/storage/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,234 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ebea008{/storage/rdd,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,235 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1787f2a0{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,235 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@163370c2{/environment,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,235 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7905a0b8{/environment/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,236 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@389b0789{/executors,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,236 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478db956{/executors/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,237 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c667f46{/executors/threadDump,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,237 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b50df34{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,245 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2462cb01{/static,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,246 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@452e19ca{/,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,246 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f8e8894{/api,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,247 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@e25951c{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,247 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@471a9022{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-08-02 16:03:53,249 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://wiki.run.definesys.com:30128
2022-08-02 16:03:53,325 WARN config.package: Can not load the default value of `spark.yarn.isHadoopProvided` from `org/apache/spark/deploy/yarn/config.properties` with error, java.lang.NullPointerException. Using `false` as a default value.
2022-08-02 16:03:53,386 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
2022-08-02 16:03:53,618 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers
2022-08-02 16:03:54,067 INFO conf.Configuration: resource-types.xml not found
2022-08-02 16:03:54,068 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-08-02 16:03:54,075 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
2022-08-02 16:03:54,075 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2022-08-02 16:03:54,075 INFO yarn.Client: Setting up container launch context for our AM
2022-08-02 16:03:54,075 INFO yarn.Client: Setting up the launch environment for our AM container
2022-08-02 16:03:54,079 INFO yarn.Client: Preparing resources for our AM container
2022-08-02 16:03:54,112 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2022-08-02 16:03:55,534 INFO yarn.Client: Uploading resource file:/tmp/spark-d95215aa-f65b-4bf6-90d7-fe5a4ae36b7f/__spark_libs__2212224271422545597.zip -> hdfs://localhost:9000/user/dehoop/.sparkStaging/application_1659427198591_0002/__spark_libs__2212224271422545597.zip
2022-08-02 16:03:56,184 INFO yarn.Client: Uploading resource file:/tmp/spark-d95215aa-f65b-4bf6-90d7-fe5a4ae36b7f/__spark_conf__752865173495706534.zip -> hdfs://localhost:9000/user/dehoop/.sparkStaging/application_1659427198591_0002/__spark_conf__.zip
2022-08-02 16:03:56,637 INFO spark.SecurityManager: Changing view acls to: dehoop
2022-08-02 16:03:56,637 INFO spark.SecurityManager: Changing modify acls to: dehoop
2022-08-02 16:03:56,637 INFO spark.SecurityManager: Changing view acls groups to: 
2022-08-02 16:03:56,637 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-08-02 16:03:56,637 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dehoop); groups with view permissions: Set(); users  with modify permissions: Set(dehoop); groups with modify permissions: Set()
2022-08-02 16:03:56,662 INFO yarn.Client: Submitting application application_1659427198591_0002 to ResourceManager
2022-08-02 16:03:56,842 INFO impl.YarnClientImpl: Submitted application application_1659427198591_0002
2022-08-02 16:03:57,846 INFO yarn.Client: Application report for application_1659427198591_0002 (state: ACCEPTED)
2022-08-02 16:03:57,848 INFO yarn.Client: 
         client token: N/A
         diagnostics: [Tue Aug 02 16:03:57 +0800 2022] Scheduler has assigned a container for AM, waiting for AM container to be launched
         ApplicationMaster host: N/A
         ApplicationMaster RPC port: -1
         queue: default
         start time: 1659427436754
         final status: UNDEFINED
         tracking URL: http://localhost:8088/proxy/application_1659427198591_0002/
         user: dehoop
2022-08-02 16:03:58,851 INFO yarn.Client: Application report for application_1659427198591_0002 (state: ACCEPTED)
2022-08-02 16:03:59,854 INFO yarn.Client: Application report for application_1659427198591_0002 (state: ACCEPTED)
2022-08-02 16:04:00,857 INFO yarn.Client: Application report for application_1659427198591_0002 (state: RUNNING)
2022-08-02 16:04:00,857 INFO yarn.Client: 
         client token: N/A
         diagnostics: N/A
         ApplicationMaster host: 192.168.66.66
         ApplicationMaster RPC port: -1
         queue: default
         start time: 1659427436754
         final status: UNDEFINED
         tracking URL: http://localhost:8088/proxy/application_1659427198591_0002/
         user: dehoop
2022-08-02 16:04:00,858 INFO cluster.YarnClientSchedulerBackend: Application application_1659427198591_0002 has started running.
2022-08-02 16:04:01,049 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39764.
2022-08-02 16:04:01,049 INFO netty.NettyBlockTransferService: Server created on wiki.run.definesys.com:39764
2022-08-02 16:04:01,051 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-08-02 16:04:01,056 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, wiki.run.definesys.com, 39764, None)
2022-08-02 16:04:01,058 INFO storage.BlockManagerMasterEndpoint: Registering block manager wiki.run.definesys.com:39764 with 912.3 MiB RAM, BlockManagerId(driver, wiki.run.definesys.com, 39764, None)
2022-08-02 16:04:01,060 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, wiki.run.definesys.com, 39764, None)
2022-08-02 16:04:01,061 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, wiki.run.definesys.com, 39764, None)
2022-08-02 16:04:01,077 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71329995{/metrics/json,null,AVAILABLE,@Spark}
2022-08-02 16:04:01,149 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> localhost, PROXY_URI_BASES -> http://localhost:8088/proxy/application_1659427198591_0002), /proxy/application_1659427198591_0002
2022-08-02 16:04:01,835 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2022-08-02 16:04:05,249 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.66.66:37116) with ID 1,  ResourceProfileId 0
2022-08-02 16:04:05,354 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:41304 with 2004.6 MiB RAM, BlockManagerId(1, localhost, 41304, None)
2022-08-02 16:04:06,903 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.66.66:37160) with ID 2,  ResourceProfileId 0
2022-08-02 16:04:06,996 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:40611 with 2004.6 MiB RAM, BlockManagerId(2, localhost, 40611, None)
2022-08-02 16:04:07,001 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-08-02 16:04:07,378 INFO concurrent.ThreadPoolTaskExecutor: Initializing ExecutorService 'applicationTaskExecutor'
2022-08-02 16:04:07,801 INFO http11.Http11NioProtocol: Starting ProtocolHandler ["http-nio-30156"]
2022-08-02 16:04:07,823 INFO tomcat.TomcatWebServer: Tomcat started on port(s): 30156 (http) with context path '/spark-star'
2022-08-02 16:04:07,826 INFO plugin.StarApplication: Started StarApplication in 19.549 seconds (JVM running for 20.039)
2022-08-02 16:04:19,788 INFO [localhost].[/spark-star]: Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-08-02 16:04:19,788 INFO servlet.DispatcherServlet: Initializing Servlet 'dispatcherServlet'
2022-08-02 16:04:19,799 INFO servlet.DispatcherServlet: Completed initialization in 11 ms
```

###### 插件关闭

```bash
spark-star stop
```
