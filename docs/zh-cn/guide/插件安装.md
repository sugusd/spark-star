##### 插件安装

###### 下载代码

```bash
git clone https://github.com/ispong/spark-star.git
```

###### 配置编译环境变量

```bash
vim /etc/profile
```

```bash
export HADOOP_HOME=/opt/hadoop
export SPARK_HOME=/opt/spark
export HADOOP_CLASSPATH=/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/* 
export HIVE_HOME=/opt/hive
```

```bash
source /etc/profile
```

###### 编译项目

```bash
bash build.sh
```

###### 配置环境变量

```bash
sudo ln -s /home/ispong/flink-acorn/build/star /opt/spark-star
```


```bash
spark-star config
```

```yaml
server:
  port: 30156 # 端口号
  servlet:
    context-path: /spark-star  # 禁止修改!!!

star:
  plugin:
    server-key: star-key # 密钥
    app-name-prefix: spark-star # app应用名字
    master: yarn # 默认启用yarn模式
    spark-config:
      spark.ui.port: 30128
      spark.executor.memory: 4g
      spark.executor.cores: 1
      spark.driver.memory: 1g
      spark.num.executors: 1
      hive.metastore.uris: thrift://localhost:9083
```
