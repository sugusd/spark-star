#### 前提

- [Hadoop(3.2.4)单节点安装](https://ispong.isxcode.com/hadoop/hadoop/hadoop%20%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85/)
- [Hadoop开启jobhistory](https://ispong.isxcode.com/hadoop/hadoop/hadoop%20Jobhistory/)
- [Spark(3.1.1)单节点安装](https://ispong.isxcode.com/hadoop/spark/spark%20%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85/)
- [Spark开启HistoryServer](https://ispong.isxcode.com/hadoop/spark/spark%20HistoryServer/)
- [Hive(3.1.2)单节点安装](https://ispong.isxcode.com/hadoop/hive/hive%20%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85/)
- [安装maven(3.8.6)](https://ispong.isxcode.com/spring/maven/maven%20%E5%AE%89%E8%A3%85/)
- [安装git](https://ispong.isxcode.com/github/git/git%20%E5%AE%89%E8%A3%85/)

###### 下载代码

> 推荐使用gitee下载
> `git clone https://gitee.com/ispong/spark-star.git`

```bash
git clone https://github.com/ispong/spark-star.git
```

###### 编译项目

```bash
mvn clean package -DskipTests
```

###### 配置环境变量

> 打包位置 `spark-star/star-dist/target/spark-star-1.2.0-bin/spark-star-1.2.0`

```bash
sudo ln -s /home/ispong/spark-star/star-dist/target/spark-star-1.2.0-bin/spark-star-1.2.0 /opt/star
sudo vim /etc/profile
```

```bash
export STAR_HOME=/opt/star
export PATH=$PATH:$STAR_HOME/bin
```

```bash
source /etc/profile
```

###### 修改配置

```bash
spark-star config
```

```yaml
server:
  port: 30156 
  
star:
  secret: star-key
```

###### 插件启动

```bash
star start
```

```log

```

###### 插件关闭

```bash
star stop
```
